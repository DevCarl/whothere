---
title: "Linear_regression_report"
author: "Silvia Saloni"
date: "Monday, August 01, 2016"
output:
  pdf_document:
    fig_height: 8
    fig_width: 14
---

#Introduction

The aim of the project was to be able to find a model that best predict the relationship between:
* the number of people counted with the survey for a given class at a particular hour 
* Wi-fi log counted in that room at that hour

This will allow to see whether Wi-Fi log is a good predictor for estimating occupancy in a classroom.

We first tried to see if the relationship between this two variables was linear. To do so we run a linear regression.

Below we describes step by step all the analysis performed.

## ANALYSIS

First of all, we set up the connection to the database, using the following code:

```{r}
connection <- dbConnect(MySQL(),user="root", password="",dbname="who_there_db", host="localhost")
```  
Then we made a query to the database, in order to get all the groundth truth data collected in room B.002, B.004 and B.006 from 9 to 17 and the correspondent Wi-Fi Log measured in that time frame and rooms. 

```{r, echo=FALSE, warning=FALSE}
query <-"SELECT W.`Room_Room_id` as Room, W.`Date`, HOUR( W.Time ) as Time, T.`Module_Module_code` as Module, M.`Course_Level`,T.`Tutorial`, T.`Double_module`, T.`Class_went_ahead`, R.`Capacity`, G.`Percentage_room_full`, AVG(W.`Associated_client_counts`) as Wifi_Average_logs, MAX(W.`Authenticated_client_counts`) as Wifi_Max_logs FROM Room R, Wifi_log W, Ground_truth_data G, Time_table T, Module M WHERE W.Room_Room_id = R.Room_id AND G.Room_Room_id = W.Room_Room_id AND W.Date = G.Date AND HOUR( W.Time ) = HOUR( G.Time ) AND HOUR( W.Time ) = HOUR( T.Time_period ) AND T.Date = W.Date AND T.Room_Room_id = W.Room_Room_id AND M.`Module_code` = T.`Module_Module_code` GROUP BY W.Room_Room_id, HOUR( W.Time ) , W.Date"

#select the data based on the query and store them in a dataframe called Analysis table
AnalysisTable <-dbGetQuery(connection, query)  
```

The dataset created had in total 216 rows and it will allow us to explore if Wi-Fi log is a good predictor of the observed occupancy of the room in a certain hour.

As a **target features** for our linear regression we decided to use the number of associated client, calculated multiplying the percentage of the room full with the capacity of the room.
```{r, echo=FALSE,warning=FALSE}
#create the new column for getting number of people counted through ground truth data
AnalysisTable$Survey_occupancy <- AnalysisTable$Capacity * AnalysisTable$Percentage_room_full
```
As response variables or feature we considered Wi-Fi logs, which were summarised either as average of the logs counted for each room and for each hour or as maximum of the logs measured for each room and for each hour. 

Together with the Wi-Fi log, we included in the data set the following features: 

* **Date**, which we did not use in this analysis, because they just cover 2 weeks of Novemeber, but for future analyses they can be used to group observations by seasons or semesters or to finds seasonal trends for time series analyses.

* **Time**, which will be explored either as continous variable and as categorical to explore if the time of the day can have an affect on the Wi-Fi log. To do so we, bin the time in 4 ranges: early morning (9-11), late morning (11-13), early afternoon (13-15) and late afternoon (15-17). This will allow us to see if the Wi-Fi log accuracy was changing during the day. For example, it is more likely that all the electronic devices are fully powered early in the morning and consequently the Wi-fi log data can be more accurate or overestimating the occupancy of the room (i.e. more than one device per person). On the contrary in the afternoon, the devices may be more likely to be out of battery and it is possible that there are less devices in the room.
```{r, echo=FALSE, warning=FALSE}
AnalysisTable$Factor_Time <-cut(AnalysisTable$Time, breaks = 4, right=FALSE, labels=c('Early Morning','Late Morning','Early Afternoon','Late Afternoon' ))
```

* **Module**, which we are not going to include it in the analysis because the majority of the module present are for computer science. For future analyses it will be possible to explore if the accuracy of Wi-fi log in predicting the occupancy change across the courses. Science courses (especially computer science courses) will be more likely to use electronic devices during lectures than art students.

* **Course level**, which can indicate us whether electronic devices will be less used during different course levels. For example, first and second level courses can be more theoretical than the upper levels. Therefore, we might expect less connections. However, undergraduates might be more distracted during lectures and look at their phones. This will result in an increase of connections in that hour.

```{r, echo=FALSE, warning=FALSE}
AnalysisTable$Course_Level <- factor(AnalysisTable$Course_Level)
```

* **Tutorial**, which can affect the number of logged people. First of all, because tutorial divided the room in 2 and therefore there will be measured less people than expected. 
```{r, echo=FALSE, warning=FALSE}
AnalysisTable$Double_module <- factor(AnalysisTable$Double_module)
AnalysisTable$Class_went_ahead <- factor(AnalysisTable$Class_went_ahead)
```

* **Double_module**, categorical variable indicating whether in the class there are more than one module, increasing the number of people expected in the room.
```{r, echo=FALSE}
AnalysisTable$Double_module <- factor(AnalysisTable$Double_module)
```

* **class_went_ahead**, categorical variable indicating whether in the class went ahead to check for false positive.
```{r, echo=FALSE}
AnalysisTable$Class_went_ahead <- factor(AnalysisTable$Class_went_ahead)
```

The resulting data set is printed below:
```{r}
head(AnalysisTable)
```

## DATA QUALITY REPORT

Before running any analyses, we carried out the data quality report to check for any issue related to the variables (e.g. outlier, skewed distribution, NaN values) and we planned the solutions that we implemented to solve them.

Initially we set all the categorical variables as factors and then we printed the descriptive statistics for all the features.
```{r}
summary(AnalysisTable)
```
From this we could see that NaN values were not present in the data set. 
We could notice that the observations for the features Tutorials and Double_model were not even distributed across the 2 levels of the variables. In fact, only 6 observations were present for tutorial class and for double module class. Therefore, we decided to discard both the features, because they will be not informative for the analysis. Similarly for the feature class_went_ahead the majority of the lectures did not have similar distribution of the observations and we decided to discard it.
Furthermore, for the variables Wifi_Average_clients, Wifi_Max_clients and Survey_occupancy it seems that there were few outliers, since the median is lower than the mean and the max values were far higher than the mean values. We will going to explore this issues with histogram and boxplots.

### Exploratory graphs

For exploring possible issues related with the continuous variables we plotted histograms and boxplots.

### Histograms

```{r, echo=FALSE,warning=FALSE}
histo1 <- ggplot(AnalysisTable, aes(x = Wifi_Max_clients)) + geom_histogram(binwidth = 10,  col="red", aes(fill=..count..)) + scale_fill_gradient("Count", low = "yellow", high = "red") +theme_bw()+theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) 

#histogram for showing the count in each bin for the Average number of clients
histo2 <- ggplot(AnalysisTable, aes(x = Wifi_Average_clients)) + geom_histogram(binwidth = 10,  col="red", aes(fill=..count..)) + scale_fill_gradient("Count", low = "yellow", high = "red") +th#histogram for showing the count in each bin for the Maximum number of clients
histo1 <- ggplot(AnalysisTable, aes(x = Wifi_Max_logs)) + geom_histogram(binwidth = 10,  col="red", aes(fill=..count..)) + scale_fill_gradient("Count", low = "yellow", high = "red") +theme_bw()+theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) 

#histogram for showing the count in each bin for the Average number of clients
histo2 <- ggplot(AnalysisTable, aes(x = Wifi_Average_logs)) + geom_histogram(binwidth = 10,  col="red", aes(fill=..count..)) + scale_fill_gradient("Count", low = "yellow", high = "red") +theme_bw()+theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) 

#histogram for showing the count in each bin for the number of clients counted with the survey
histo3 <- ggplot(AnalysisTable, aes(x = Survey_occupancy)) + geom_histogram(binwidth = 10,  col="red", aes(fill=..count..)) + scale_fill_gradient("Count", low = "yellow", high = "red") +theme_bw()+theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) 

#histogram for showing the count in each bin for each hour of the day
histo4 <- ggplot(AnalysisTable, aes(x = Time)) + geom_histogram(binwidth = 2,  col="red", aes(fill=..count..)) + scale_fill_gradient("Count", low = "yellow", high = "red") +theme_bw()+theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) 

#plot all the histograms in one window
multiplot(histo1, histo2, histo3, histo4, cols=2)
```  
<br><br><br>
Form the histograms we could see that the distribution of the feature Wifi Maximum_client (i.e. the Maximum number of devices logged in one hour lecture) was skewed to the left, indicating that no more than 40 people attended the majority of the lectures. Furthermore, we could see that there were potential outliers (values > 150). Similar patterns were observed for the feature Wifi_Average_clients.
Different was the situation of the target feature, Survey_counted client, which showed a skewed distribution, but more scattered, similar to a Poisson distribution. This could cause a problem in running a linear regression and more likely we have have to run a generalise linear model with a Poisson distribution. This is not surprising, since we are dealing with count data (Zuur et al. 2009).
Feature times had as well a skewed distribution, suggesting that the majority of the lectures were concentrating during the early morning and they were decreasing towards the afternoon.
<br><br><br>

#### Boxplots
<br>
  
```{r, echo=FALSE, warning=FALSE}
box1 <- ggplot(AnalysisTable, aes(x = factor(0), y = Survey_occupancy)) + geom_boxplot() + xlab("Counted clients") + ylab("")+ scale_x_discrete(breaks = NULL) + theme_bw()+theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) 

#box plot for the counted clients variable
box2 <- ggplot(AnalysisTable, aes(x = factor(0), y = Wifi_Average_logs)) + geom_boxplot() + xlab("Average counted clients") + ylab("")+ scale_x_discrete(breaks = NULL)  + theme_bw()+theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) 

#box plot for the maximum number of clients variable
box3 <- ggplot(AnalysisTable, aes(x = factor(0), y =Wifi_Max_logs)) + geom_boxplot() + xlab("Maximum counted clients") + ylab("")+ scale_x_discrete(breaks = NULL) + theme_bw()+theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) 

#box plot for the Time continuous variable
box4 <- ggplot(AnalysisTable, aes(x = factor(0), y = Time)) + geom_boxplot() + xlab("Time") + ylab("")+ scale_x_discrete(breaks = NULL) + theme_bw()+theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) 
#plot all the boxplots in one window
multiplot(box1, box2, box3, box4, cols=2)
```  
<br><br>

From the boxplots, all the trends observed in the histograms were confirmed.

For categorical variables we plotted bar plot graphs.  

#### Bar plots  

```{r, echo=FALSE, warning=FALSE}

bar1 <- ggplot(AnalysisTable, aes(x = Room)) + geom_bar(fill="orangered2")+ theme_bw()+theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) 

#bar plot for the categorical variable: Course level
bar2 <- ggplot(AnalysisTable, aes(x = Course_Level)) + geom_bar(fill="orangered2")+ theme_bw()+theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) 

#bar plot for the categorical variable: Time as factor
bar3 <- ggplot(AnalysisTable, aes(x = Factor_Time)) + geom_bar(fill="orangered2")+ theme_bw()+theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) 

#plot all the barplots in one window
multiplot(bar1, bar2, bar3, cols=2)
```
<br><br>
From the barplots, we could see that observations were equally distributed across all the levels of the feature Room and Factor Time. On the contrary, there were more observations for non lectures and level 3 courses. No issues were detected for those features.  

#### Summary
<br><br>

Features               | Issues                                   | Planned Solution             
-----------------------|------------------------------------------|----------------------------
Room                   |None                                      |None
Time                   |Distibution skewed to the left            |To solve during analysis 
Factor Time            |None                                      |None
Course level           |None                                      |None
Tutorial               |Uneven representation of the level        |Discarded from the analysis
Double Module          |Uneven representation of the level        |Discarded from the analysis
Class went ahead       |Uneven representation of the level        |Discarded from the analysis
Wifi Average clients   |Distibution skewed to the left \& outliers|To solve during analysis
Wifi Maximum clients   |Distibution skewed to the left \& outliers|To solve during analysis
Survey Counted clients |Distibution skewed to the left \& outliers|To solve during analysis

<br><br>

## FEATURES AFFECTING THE TARGET FEATURE  

The next step of the analysis was to see which feature really affect the target feature for exploring which features were more likely to affect the occupancy .  
For the continuous features we explored the effects on the target features using a correlation matrix, while for the categorical features we used box plots. 

### Correlation matrix for continuous variables.  
<br>
```{r, echo=FALSE, warning=FALSE}
# Correlation Matrix

my_fn <- function(data, mapping, ...){
  p <- ggplot(data = data, mapping = mapping) + 
    geom_point() + 
    geom_smooth(method=lm, fill="orangered3", color="orangered3", ...)
  p
}

ggpairs(AnalysisTable, columns = c('Survey_occupancy','Wifi_Max_logs', 'Wifi_Average_logs', 'Time'), lower = list(continuous = my_fn)) + theme_bw()
```  
<br><br>
From the correlation matrix Survey counted  clients seems to have a good correlation with Wifi Average counted clients and Maximum counted clients, therefore we are will try to run 2 models: one for exploring the relationship between Survey counted clients and Average counted clients and another for Survey counted clients and Maximum counted clients. However, from this graphs we can see that there is one point that is clearly two outliers. Therefore, we are going to run the analyses with and without them.

From the graphs we can see that Average counted clients and Maximum counted clients are highly correlated showing that both of them are not so different. Therefore we will not expect too much difference among the 2 models.

Time does not seems to be correlated with the target features Survey counted clients and it seems more categorical.  

### Box plots for categorical variables.  
``` {r, echo=FALSE, warning=FALSE}
#Box plot for exploring relationship between Room and Client count
pairbox1 <- ggplot(AnalysisTable, aes(x = Room, y = Survey_counted_clients)) + geom_boxplot() + theme_bw()+ theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))

#Box plot for exploring relationship between Room and time as a factor
pairbox2 <- ggplot(AnalysisTable, aes(x = Factor_Time, y =Survey_counted_clients)) + geom_boxplot() + theme_bw()+ theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))

#Box plot for exploring relationship between Room and course level
pairbox3 <- ggplot(AnalysisTable, aes(x = Course_Level, y =Survey_counted_clients)) + geom_boxplot()+  theme_bw()+ theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))

#plot all the boxplots in one window
multiplot(pairbox1, pairbox2, pairbox3, cols=2)
``` 
<br><br>
From the boxplot plotting the counted people in the different room, it can be observed that the average of the counted people in room 1 was not different from room2. Room3 had an higher number of people on average, but this can be due to the outlier. For this reasons we are going to consider its effect.
The average number of counted people, instead, changed across the different course levels and it will be worth to explore if the occupancy of the room was affected by the course level.
The highest average number of counted people was in the late morning around 50, while it was around 30 for the rest of the day. Therefore it will be interesting to explore the effect of the time on the occupancy.

# Analysis
<br>
For selecting the features that together with the max logs or with the average logs best predict the ground truth data we will do model selection using 10 folds cross validation, with a method similar to the one used by James et al. (2013).  
For doing so, instead, of using the function regsubset for selecting all the possible models, we decided to considered only the models that better suits our hypothesis. Therefore, we run the following models:

* $Survey occupancy \~ 1$, the null model;

* $Survey occupancy \~ Average Wifi occupancy$, for testing whether average Wi-Fi counting logs were accurately predicting the occupancy of the room;

* $Survey occupancy \~ Average Wifi occupancy + Room$, for testing whether average Wi-Fi counting logs and the room were were accurately predicting the occupancy of the room;

* $Survey occupancy \~ Average Wifi occupancy + Time$, for testing whether average Wi-Fi counting logs and the time of the day were accurately predicting the occupancy of the room;

* $Survey occupancy \~ Average Wifi occupancy + Course_Level$, for testing whether average Wi-Fi counting logs and course levels were accurately predicting the occupancy of the room;

* $Survey occupancy \~ Average Wifi occupancy + Room + Time$, for testing whether average Wi-Fi counting logs, room type and the time of the day were accurately predicting the occupancy of the room;
* $Survey occupancy \~ Average Wifi occupancy + Room + Course_Level$, for testing whether average Wi-Fi counting logs, room type and course levels were accurately predicting the occupancy of the room;
* $Survey occupancy \~ Average Wifi occupancy + Time + Course_Level$, for testing whether average Wi-Fi counting logs, the time of the day and the course levels were accurately predicting the occupancy of the room;

* $Survey occupancy \~ Average Wifi occupancy + Room + Time + Course_Level$, for testing whether average Wi-Fi counting logs, rooms, the time of the day and the course levels were accurately predicting the occupancy of the room;

The same model were run with the occupancy estimated with the maximum number of logs measured in that hour. All these model were run using the k fold cross. K fold validation was preferred over the validation set approach and the Leave Out Cross Validation (LOOCV), because it is more robust and more accurate in estimating the test error. The Validation set approach tends to give an over estimate of the test error and the test error is dependent on the observations included randomly in the test set. Furthermore, the LOOCV tends to provide a test error with a high variance, because the folds used to calculating it are correlated among each other. 
In particular in this analysis we are going to perform a 10 fold cross validation, which is pretty standard.

The 10 fold cross validation was carried out with the package, CVglm. For each model we estract the overall mean square error(MSE) and we picked as best model the model with the lowest MSE.

#Results

#CASE 1: MODEL SELECTION WITH RESPONSE VARIABLE AVERAGE CLIENTS

null.model <- CVlm (data=AnalysisTable, m= 10, form.lm = formula (Survey_occupancy ~ 1))

lm.avg <- CVlm (data=AnalysisTable, m= 10, form.lm = formula (Survey_occupancy ~ Wifi_Average_logs))

lm.avg.room <- CVlm (data=AnalysisTable, m= 10, form.lm = formula (Survey_occupancy ~ Wifi_Average_logs + Room))

lm.avg.time <- CVlm (data=AnalysisTable, m= 10, form.lm = formula (Survey_occupancy ~ Wifi_Average_logs + Factor_Time))

lm.avg.level <- CVlm (data=AnalysisTable, m= 10, form.lm = formula (Survey_occupancy ~ Wifi_Average_logs + Course_Level))

lm.avg.room.time <- CVlm (data=AnalysisTable, m= 10, form.lm = formula (Survey_occupancy ~ Wifi_Average_logs + Room + Factor_Time))

lm.avg.room.level <- CVlm (data=AnalysisTable, m= 10, form.lm = formula (Survey_occupancy ~ Wifi_Average_logs + Room + Course_Level))

lm.avg.time.level <- CVlm (data=AnalysisTable, m= 10, form.lm = formula (Survey_occupancy ~ Wifi_Average_logs + Factor_Time + Course_Level))

lm.avg.full <- CVlm (data=AnalysisTable, m= 10, form.lm = formula (Survey_occupancy ~ Wifi_Average_logs + Room + Factor_Time + Course_Level))

#the overall mse of the null model is:
attr(null.model, "ms")
#the overall mse of the lm.avg model is:
attr(lm.avg, "ms")
#the overall mse of the lm.avg.room model is:
attr(lm.avg.room, "ms")
#the overall mse of the lm.avg.time model is:
attr(lm.avg.time, "ms")
#the overall mse of the lm.avg.level model is:
attr(lm.avg.level, "ms")
#the overall mse of the lm.avg.room model is:
attr(lm.avg.room.time, "ms")
#the overall mse of the lm.avg.room.level model is:
attr(lm.avg.room.level, "ms")
#the overall mse of the lm.avg.time.level model is:
attr(lm.avg.time.level, "ms")
#the overall mse of the avg.full model is:
attr(lm.avg.full, "ms")

#The model with the lowest MSE was the model with only the average logs (343)

#CASE 2: MODEL SELECTION WITH RESPONSE VARIABLE MAX CLIENTS

null.model.max <- CVlm (data=AnalysisTable, m= 10, form.lm = formula (Survey_occupancy ~ 1))

lm.max <- CVlm (data=AnalysisTable, m= 10, form.lm = formula (Survey_occupancy ~ Wifi_Max_logs))

lm.max.room <- CVlm (data=AnalysisTable, m= 10, form.lm = formula (Survey_occupancy ~ Wifi_Max_logs + Room))

lm.max.time <- CVlm (data=AnalysisTable, m= 10, form.lm = formula (Survey_occupancy ~ Wifi_Max_logs + Factor_Time))

lm.max.level <- CVlm (data=AnalysisTable, m= 10, form.lm = formula (Survey_occupancy ~ Wifi_Max_logs + Course_Level))

lm.max.room.time <- CVlm (data=AnalysisTable, m= 10, form.lm = formula (Survey_occupancy ~ Wifi_Max_logs + Room + Factor_Time))

lm.max.room.level <- CVlm (data=AnalysisTable, m= 10, form.lm = formula (Survey_occupancy ~ Wifi_Max_logs + Room + Course_Level))

lm.max.time.level <- CVlm (data=AnalysisTable, m= 10, form.lm = formula (Survey_occupancy ~ Wifi_Max_logs + Factor_Time + Course_Level))

lm.max.full <- CVlm (data=AnalysisTable, m= 10, form.lm = formula (Survey_occupancy ~ Wifi_Max_logs + Room + Factor_Time + Course_Level))

#the overall mse of the null model is:
attr(null.model.max, "ms")
#the overall mse of the lm.avg model is:
attr(lm.max, "ms")
#the overall mse of the lm.avg.room model is:
attr(lm.max.room, "ms")
#the overall mse of the lm.avg.time model is:
attr(lm.max.time, "ms")
#the overall mse of the lm.avg.level model is:
attr(lm.max.level, "ms")
#the overall mse of the lm.avg.room model is:
attr(lm.max.room.time, "ms")
#the overall mse of the lm.avg.room.level model is:
attr(lm.max.room.level, "ms")
#the overall mse of the lm.avg.time.level model is:
attr(lm.max.time.level, "ms")
#the overall mse of the avg.full model is:
attr(lm.max.full, "ms")

#The model with the lowest MSE was the model with only the max logs as response variable (373), which was slightly higher than the previous best model.
#Therefore we are going to run the Survey_occupancy ~ Wifi_Average_logs on the whole model
occupancy.lm.avg <- lm(Survey_occupancy ~ Wifi_Average_logs, data=AnalysisTable)
summary(occupancy.lm.avg)
#plot the residual
plot(occupancy.lm.avg)


